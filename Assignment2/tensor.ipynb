{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Introduction to Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/tensor\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/tensor.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/tensor.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/tensor.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AL2hzxorJiWy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ3s2J8Vgowq"
      },
      "source": [
        "Tensors are multi-dimensional arrays with a uniform type (called a `dtype`).  You can see all supported `dtypes` at `tf.dtypes.DType`.\n",
        "\n",
        "If you're familiar with [NumPy](https://numpy.org/devdocs/user/quickstart.html){:.external}, tensors are (kind of) like `np.arrays`.\n",
        "\n",
        "All tensors are immutable like Python numbers and strings: you can never update the contents of a tensor, only create a new one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRK5-9EpYbzG"
      },
      "source": [
        "## Basics\n",
        "\n",
        "First, create some basic tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSHRFT6LJbxq"
      },
      "source": [
        "Here is a \"scalar\" or \"rank-0\" tensor . A scalar contains a single value, and no \"axes\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d5JcgLFR6gHv",
        "outputId": "f3d84a2b-1c39-41e9-8ed5-71e58314c698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e9bd249e5b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This will be an int32 tensor by default; see \"dtypes\" below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrank_0_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_0_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "# This will be an int32 tensor by default; see \"dtypes\" below.\n",
        "rank_0_tensor = tf.constant(4)\n",
        "print(rank_0_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdmPAn9fWYs5"
      },
      "source": [
        "A \"vector\" or \"rank-1\" tensor is like a list of values. A vector has one axis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZos8o_R6oE7"
      },
      "outputs": [],
      "source": [
        "# Let's make this a float tensor.\n",
        "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
        "print(rank_1_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3IJG-ug_H4u"
      },
      "source": [
        "A \"matrix\" or \"rank-2\" tensor has two axes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnOIA_xb6u0M"
      },
      "outputs": [],
      "source": [
        "# If you want to be specific, you can set the dtype (see below) at creation time\n",
        "rank_2_tensor = tf.constant([[1, 2],\n",
        "                             [3, 4],\n",
        "                             [5, 6]], dtype=tf.float16)\n",
        "print(rank_2_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19m72qEPkfxi"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>A scalar, shape: <code>[]</code></th>\n",
        "  <th>A vector, shape: <code>[3]</code></th>\n",
        "  <th>A matrix, shape: <code>[3, 2]</code></th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/scalar.png?raw=1\" alt=\"A scalar, the number 4\" />\n",
        "  </td>\n",
        "\n",
        "  <td>\n",
        "   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/vector.png?raw=1\" alt=\"The line with 3 sections, each one containing a number.\"/>\n",
        "  </td>\n",
        "  <td>\n",
        "   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/matrix.png?raw=1\" alt=\"A 3x2 grid, with each cell containing a number.\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjFvzcn4_ehD"
      },
      "source": [
        "Tensors may have more axes; here is a tensor with three axes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sesW7gw6JkXy"
      },
      "outputs": [],
      "source": [
        "# There can be an arbitrary number of\n",
        "# axes (sometimes called \"dimensions\")\n",
        "rank_3_tensor = tf.constant([\n",
        "  [[0, 1, 2, 3, 4],\n",
        "   [5, 6, 7, 8, 9]],\n",
        "  [[10, 11, 12, 13, 14],\n",
        "   [15, 16, 17, 18, 19]],\n",
        "  [[20, 21, 22, 23, 24],\n",
        "   [25, 26, 27, 28, 29]],])\n",
        "\n",
        "print(rank_3_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM2sTGIkoE3S"
      },
      "source": [
        "There are many ways you might visualize a tensor with more than two axes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFiYfNMMhDgL"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=3>A 3-axis tensor, shape: <code>[3, 2, 5]</code></th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_numpy.png?raw=1\"/>\n",
        "  </td>\n",
        "  <td>\n",
        "   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_front.png?raw=1\"/>\n",
        "  </td>\n",
        "\n",
        "  <td>\n",
        "   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_block.png?raw=1\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWAc0U8OZwNb"
      },
      "source": [
        "You can convert a tensor to a NumPy array either using `np.array` or the `tensor.numpy` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5u6_6ZYaS7B"
      },
      "outputs": [],
      "source": [
        "np.array(rank_2_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6Taz2gIaZeo"
      },
      "outputs": [],
      "source": [
        "rank_2_tensor.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnz19F0ocEKD"
      },
      "source": [
        "Tensors often contain floats and ints, but have many other types, including:\n",
        "\n",
        "* complex numbers\n",
        "* strings\n",
        "\n",
        "The base `tf.Tensor` class requires tensors to be \"rectangular\"---that is, along each axis, every element is the same size.  However, there are specialized types of tensors that can handle different shapes:\n",
        "\n",
        "* Ragged tensors (see [RaggedTensor](#ragged_tensors) below)\n",
        "* Sparse tensors (see [SparseTensor](#sparse_tensors) below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDC7OGeAIJr8"
      },
      "source": [
        "You can do basic math on tensors, including addition, element-wise multiplication, and matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DTkjwDOIIDa"
      },
      "outputs": [],
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "b = tf.constant([[1, 1],\n",
        "                 [1, 1]]) # Could have also said `tf.ones([2,2])`\n",
        "\n",
        "print(tf.add(a, b), \"\\n\")\n",
        "print(tf.multiply(a, b), \"\\n\")\n",
        "print(tf.matmul(a, b), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2smoWeUz-N2q"
      },
      "outputs": [],
      "source": [
        "print(a + b, \"\\n\") # element-wise addition\n",
        "print(a * b, \"\\n\") # element-wise multiplication\n",
        "print(a @ b, \"\\n\") # matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3_vIAl2JPVc"
      },
      "source": [
        "Tensors are used in all kinds of operations (or \"Ops\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp4WUYzGIbnv"
      },
      "outputs": [],
      "source": [
        "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
        "\n",
        "# Find the largest value\n",
        "print(tf.reduce_max(c))\n",
        "# Find the index of the largest value\n",
        "print(tf.math.argmax(c))\n",
        "# Compute the softmax\n",
        "print(tf.nn.softmax(c))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MNM-q7-MZLz"
      },
      "source": [
        "Note: Typically, anywhere a TensorFlow function expects a `Tensor` as input, the function will also accept anything that can be converted to a `Tensor` using `tf.convert_to_tensor`. See below for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wch0N8xNEt-"
      },
      "outputs": [],
      "source": [
        "tf.convert_to_tensor([1,2,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngqIeWYeNJVI"
      },
      "outputs": [],
      "source": [
        "tf.reduce_max([1,2,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThVMxqbVNOq3"
      },
      "outputs": [],
      "source": [
        "tf.reduce_max(np.array([1,2,3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvSAbowVVuRr"
      },
      "source": [
        "## About shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkaBIqkTCcGY"
      },
      "source": [
        "Tensors have shapes.  Some vocabulary:\n",
        "\n",
        "* **Shape**: The length (number of elements) of each of the axes of a tensor.\n",
        "* **Rank**: Number of tensor axes.  A scalar has rank 0, a vector has rank 1, a matrix is rank 2.\n",
        "* **Axis** or **Dimension**: A particular dimension of a tensor.\n",
        "* **Size**: The total number of items in the tensor, the product of the shape vector's elements.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9L3-kCQq2f6"
      },
      "source": [
        "Note: Although you may see reference to a \"tensor of two dimensions\", a rank-2 tensor does not usually describe a 2D space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOyG2tn8LhW"
      },
      "source": [
        "Tensors and `tf.TensorShape` objects have convenient properties for accessing these:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RyD3yewUKdnK"
      },
      "outputs": [],
      "source": [
        "rank_4_tensor = tf.zeros([3, 2, 4, 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTZZW9ziq4og"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=2>A rank-4 tensor, shape: <code>[3, 2, 4, 5]</code></th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/shape.png?raw=1\" alt=\"A tensor shape is like a vector.\">\n",
        "    <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/4-axis_block.png?raw=1\" alt=\"A 4-axis tensor\">\n",
        "  </td>\n",
        "  </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MHm9vSqogsBk",
        "outputId": "e89059d4-1ddd-4a52-9fd6-e4c430824ba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of every element: <dtype: 'float32'>\n",
            "Number of axes: 4\n",
            "Shape of tensor: (3, 2, 4, 5)\n",
            "Elements along axis 0 of tensor: 3\n",
            "Elements along the last axis of tensor: 5\n",
            "Total number of elements (3*2*4*5):  120\n"
          ]
        }
      ],
      "source": [
        "print(\"Type of every element:\", rank_4_tensor.dtype)\n",
        "print(\"Number of axes:\", rank_4_tensor.ndim)\n",
        "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
        "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
        "print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
        "print(\"Total number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZGZp_JOOPOv"
      },
      "source": [
        "But note that the `Tensor.ndim` and `Tensor.shape` attributes don't return `Tensor` objects. If you need a `Tensor` use the `tf.rank` or `tf.shape` function. This difference is subtle, but it can be important when building graphs (later)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ptq0-y6APCpD",
        "outputId": "c1cb2a26-21c0-482b-d9c6-e784bc0a6fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tf.rank(rank_4_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HslrDOEBPICN",
        "outputId": "0923003a-6ab8-43f1-844c-4d873793ecb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([3, 2, 4, 5], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tf.shape(rank_4_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQmE_Vx5JilS"
      },
      "source": [
        "While axes are often referred to by their indices, you should always keep track of the meaning of each. Often axes are ordered from global to local: The batch axis first, followed by spatial dimensions, and features for each location last. This way feature vectors are contiguous regions of memory.\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<th>Typical axis order</th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/shape2.png?raw=1\" alt=\"Keep track of what each axis is. A 4-axis tensor might be: Batch, Width, Height, Features\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlPoVvJS75Bb"
      },
      "source": [
        "## Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apOkCKqCZIZu"
      },
      "source": [
        "### Single-axis indexing\n",
        "\n",
        "TensorFlow follows standard Python indexing rules, similar to [indexing a list or a string in Python](https://docs.python.org/3/tutorial/introduction.html#strings){:.external}, and the basic rules for NumPy indexing.\n",
        "\n",
        "* indexes start at `0`\n",
        "* negative indices count backwards from the end\n",
        "* colons, `:`, are used for slices: `start:stop:step`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SQ-CrJxLXTIM",
        "outputId": "8f2431c7-a02a-4e9e-903a-8b7426ccadc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  2  3  5  8 13 21 34]\n"
          ]
        }
      ],
      "source": [
        "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
        "print(rank_1_tensor.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQYYL56PXSak"
      },
      "source": [
        "Indexing with a scalar removes the axis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "n6tqHciOWMt5",
        "outputId": "4b406c17-0a32-4040-ac22-56ac15a95e73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First: 0\n",
            "Second: 1\n",
            "Last: 34\n"
          ]
        }
      ],
      "source": [
        "print(\"First:\", rank_1_tensor[0].numpy())\n",
        "print(\"Second:\", rank_1_tensor[1].numpy())\n",
        "print(\"Last:\", rank_1_tensor[-1].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJLHU_a2XwpG"
      },
      "source": [
        "Indexing with a `:` slice keeps the axis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "giVPPcfQX-cu",
        "outputId": "4b9566d2-7477-4fee-b7ff-2e979bef46f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything: [ 0  1  1  2  3  5  8 13 21 34]\n",
            "Before 4: [0 1 1 2]\n",
            "From 4 to the end: [ 3  5  8 13 21 34]\n",
            "From 2, before 7: [1 2 3 5 8]\n",
            "Every other item: [ 0  1  3  8 21]\n",
            "Reversed: [34 21 13  8  5  3  2  1  1  0]\n"
          ]
        }
      ],
      "source": [
        "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
        "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
        "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
        "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
        "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
        "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elDSxXi7X-Bh"
      },
      "source": [
        "### Multi-axis indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgk0uRUYZiai"
      },
      "source": [
        "Higher rank tensors are indexed by passing multiple indices.\n",
        "\n",
        "The exact same rules as in the single-axis case apply to each axis independently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Tc5X_WlsZXmd",
        "outputId": "e306a5ec-7db3-42c7-8ab6-1942cb7f3790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]]\n"
          ]
        }
      ],
      "source": [
        "print(rank_2_tensor.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w07U9vq5ipQk"
      },
      "source": [
        "Passing an integer for each index, the result is a scalar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PvILXc1PjqTM",
        "outputId": "23794ea3-c2d9-47f1-ab36-6cbdc5be524b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0\n"
          ]
        }
      ],
      "source": [
        "# Pull out a single value from a 2-rank tensor\n",
        "print(rank_2_tensor[1, 1].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RLCzAOHjfEH"
      },
      "source": [
        "You can index using any combination of integers and slices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YTqNqsfJkJP_",
        "outputId": "dc854a00-65d0-41b0-dfff-9dffccb85409",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second row: [3. 4.]\n",
            "Second column: [2. 4. 6.]\n",
            "Last row: [5. 6.]\n",
            "First item in last column: 2.0\n",
            "Skip the first row:\n",
            "[[3. 4.]\n",
            " [5. 6.]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get row and column tensors\n",
        "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
        "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
        "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
        "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
        "print(\"Skip the first row:\")\n",
        "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P45TwSUVSK6G"
      },
      "source": [
        "Here is an example with a 3-axis tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GuLoMoCVSLxK",
        "outputId": "8565757a-f086-4d5b-dc80-40f11fbeecf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 4  9]\n",
            " [14 19]\n",
            " [24 29]], shape=(3, 2), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(rank_3_tensor[:, :, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NgmHq27TJOE"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "<th colspan=2>Selecting the last feature across all locations in each example in the batch </th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/index1.png?raw=1\" alt=\"A 3x2x5 tensor with all the values at the index-4 of the last axis selected.\">\n",
        "  </td>\n",
        "      <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/index2.png?raw=1\" alt=\"The selected values packed into a 2-axis tensor.\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9V83-thHn89"
      },
      "source": [
        "Read the [tensor slicing guide](https://tensorflow.org/guide/tensor_slicing) to learn how you can apply indexing to manipulate individual elements in your tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpr7R0t4SVb0"
      },
      "source": [
        "## Manipulating Shapes\n",
        "\n",
        "Reshaping a tensor is of great utility. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EMeTtga5Wq8j",
        "outputId": "04e1a414-c9b6-4879-ff14-5d2c2f09595c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n"
          ]
        }
      ],
      "source": [
        "# Shape returns a `TensorShape` object that shows the size along each axis\n",
        "x = tf.constant([[1], [2], [3]])\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "38jc2RXziT3W",
        "outputId": "62d84bf9-b6d9-4504-984b-bd0097c7d6e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 1]\n"
          ]
        }
      ],
      "source": [
        "# You can convert this object into a Python list, too\n",
        "print(x.shape.as_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_xRlHZMKYnF"
      },
      "source": [
        "You can reshape a tensor into a new shape. The `tf.reshape` operation is fast and cheap as the underlying data does not need to be duplicated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pa9JCgMLWy87"
      },
      "outputs": [],
      "source": [
        "# You can reshape a tensor to a new shape.\n",
        "# Note that you're passing in a list\n",
        "reshaped = tf.reshape(x, [1, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Mcq7iXOkW3LK",
        "outputId": "6abfe248-a2b4-45d9-d46c-6c99e67e4627",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n",
            "(1, 3)\n"
          ]
        }
      ],
      "source": [
        "print(x.shape)\n",
        "print(reshaped.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIB2tOkoVr6E"
      },
      "source": [
        "The data maintains its layout in memory and a new tensor is created, with the requested shape, pointing to the same data. TensorFlow uses C-style \"row-major\" memory ordering, where incrementing the rightmost index corresponds to a single step in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7kMfM0RpUgI8",
        "outputId": "c02d1872-5fb1-44b5-b4ad-bbe11cb277b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(rank_3_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcDtfQkJWzIx"
      },
      "source": [
        "If you flatten a tensor you can see what order it is laid out in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "COnHEPuaWDQp",
        "outputId": "2f86fd2b-181d-4d15-8291-680dfe6280f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29], shape=(30,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# A `-1` passed in the `shape` argument says \"Whatever fits\".\n",
        "print(tf.reshape(rank_3_tensor, [-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJZRira2W--c"
      },
      "source": [
        "Typically the only reasonable use of `tf.reshape` is to combine or split adjacent axes (or add/remove `1`s).\n",
        "\n",
        "For this 3x2x5 tensor, reshaping to (3x2)x5 or 3x(2x5) are both reasonable things to do, as the slices do not mix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "zP2Iqc7zWu_J",
        "outputId": "0ced762d-5e02-4439-afab-ed59fba0c686",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4]\n",
            " [ 5  6  7  8  9]\n",
            " [10 11 12 13 14]\n",
            " [15 16 17 18 19]\n",
            " [20 21 22 23 24]\n",
            " [25 26 27 28 29]], shape=(6, 5), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5  6  7  8  9]\n",
            " [10 11 12 13 14 15 16 17 18 19]\n",
            " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\n",
        "print(tf.reshape(rank_3_tensor, [3, -1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZsZRUhihlDB"
      },
      "source": [
        "<table>\n",
        "<th colspan=3>\n",
        "Some good reshapes.\n",
        "</th>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-before.png?raw=1\" alt=\"A 3x2x5 tensor\">\n",
        "  </td>\n",
        "  <td>\n",
        "  <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-good1.png?raw=1\" alt=\"The same data reshaped to (3x2)x5\">\n",
        "  </td>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-good2.png?raw=1\" alt=\"The same data reshaped to 3x(2x5)\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOcRxDC3jNIU"
      },
      "source": [
        "Reshaping will \"work\" for any new shape with the same total number of elements, but it will not do anything useful if you do not respect the order of the axes.\n",
        "\n",
        "Swapping axes in `tf.reshape` does not work; you need `tf.transpose` for that. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "I9qDL_8u7cBH",
        "outputId": "2cce0dfa-8bbd-41bb-f535-ac889e743f0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]]\n",
            "\n",
            " [[15 16 17 18 19]\n",
            "  [20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]\n",
            " [24 25 26 27 28 29]], shape=(5, 6), dtype=int32) \n",
            "\n",
            "InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]\n"
          ]
        }
      ],
      "source": [
        "# Bad examples: don't do this\n",
        "\n",
        "# You can't reorder axes with reshape.\n",
        "print(tf.reshape(rank_3_tensor, [2, 3, 5]), \"\\n\") \n",
        "\n",
        "# This is a mess\n",
        "print(tf.reshape(rank_3_tensor, [5, 6]), \"\\n\")\n",
        "\n",
        "# This doesn't work at all\n",
        "try:\n",
        "  tf.reshape(rank_3_tensor, [7, -1])\n",
        "except Exception as e:\n",
        "  print(f\"{type(e).__name__}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTM9-5eh68oo"
      },
      "source": [
        "<table>\n",
        "<th colspan=3>\n",
        "Some bad reshapes.\n",
        "</th>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-bad.png?raw=1\" alt=\"You can't reorder axes, use tf.transpose for that\">\n",
        "  </td>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-bad4.png?raw=1\" alt=\"Anything that mixes the slices of data together is probably wrong.\">\n",
        "  </td>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-bad2.png?raw=1\" alt=\"The new shape must fit exactly.\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9r90BvHCbTt"
      },
      "source": [
        "You may run across not-fully-specified shapes. Either the shape contains a `None` (an axis-length is unknown) or the whole shape is `None` (the rank of the tensor is unknown).\n",
        "\n",
        "Except for [tf.RaggedTensor](#ragged_tensors), such shapes will only occur in the context of TensorFlow's symbolic, graph-building  APIs:\n",
        "\n",
        "* [tf.function](function.ipynb) \n",
        "* The [keras functional API](https://www.tensorflow.org/guide/keras/functional).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDmFtFM7k0R2"
      },
      "source": [
        "## More on `DTypes`\n",
        "\n",
        "To inspect a `tf.Tensor`'s data type use the `Tensor.dtype` property.\n",
        "\n",
        "When creating a `tf.Tensor` from a Python object you may optionally specify the datatype.\n",
        "\n",
        "If you don't, TensorFlow chooses a datatype that can represent your data. TensorFlow converts Python integers to `tf.int32` and Python floating point numbers to `tf.float32`. Otherwise TensorFlow uses the same rules NumPy uses when converting to arrays.\n",
        "\n",
        "You can cast from type to type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5mSTDWbelUvu",
        "outputId": "e3aaf4ac-5c70-4a1b-c2ad-1369e63c2a9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2 3 4], shape=(3,), dtype=uint8)\n"
          ]
        }
      ],
      "source": [
        "the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)\n",
        "the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)\n",
        "# Now, cast to an uint8 and lose the decimal precision\n",
        "the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)\n",
        "print(the_u8_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1yBlJsVlFSu"
      },
      "source": [
        "## Broadcasting\n",
        "\n",
        "Broadcasting is a concept borrowed from the [equivalent feature in NumPy](https://numpy.org/doc/stable/user/basics.broadcasting.html){:.external}.  In short, under certain conditions, smaller tensors are \"stretched\" automatically to fit larger tensors when running combined operations on them.\n",
        "\n",
        "The simplest and most common case is when you attempt to multiply or add a tensor to a scalar.  In that case, the scalar is broadcast to be the same shape as the other argument. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "P8sypqmagHQN",
        "outputId": "f9eb93f6-9888-4fbc-e7d7-8f6c3b812c19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "x = tf.constant([1, 2, 3])\n",
        "\n",
        "y = tf.constant(2)\n",
        "z = tf.constant([2, 2, 2])\n",
        "# All of these are the same computation\n",
        "print(tf.multiply(x, 2))\n",
        "print(x * y)\n",
        "print(x * z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0SBoR6voWcb"
      },
      "source": [
        "Likewise, axes with length 1 can be stretched out to match the other arguments.  Both arguments can be stretched in the same computation.\n",
        "\n",
        "In this case a 3x1 matrix is element-wise multiplied by a 1x4 matrix to produce a 3x4 matrix. Note how the leading 1 is optional: The shape of y is `[4]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6sGmkPg3XANr",
        "outputId": "6ea758af-6dea-4f94-b3b4-872ab1988350",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1]\n",
            " [2]\n",
            " [3]], shape=(3, 1), dtype=int32) \n",
            "\n",
            "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# These are the same computations\n",
        "x = tf.reshape(x,[3,1])\n",
        "y = tf.range(1, 5)\n",
        "print(x, \"\\n\")\n",
        "print(y, \"\\n\")\n",
        "print(tf.multiply(x, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_7sh-EUYLrE"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>A broadcasted add: a <code>[3, 1]</code> times a <code>[1, 4]</code> gives a <code>[3,4]</code> </th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/broadcasting.png?raw=1\" alt=\"Adding a 3x1 matrix to a 4x1 matrix results in a 3x4 matrix\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V3KgSJcKDRz"
      },
      "source": [
        "Here is the same operation without broadcasting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "elrF6v63igY8",
        "outputId": "0e20bc9d-5361-4a5c-e207-a94b89fcb65e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "x_stretch = tf.constant([[1, 1, 1, 1],\n",
        "                         [2, 2, 2, 2],\n",
        "                         [3, 3, 3, 3]])\n",
        "\n",
        "y_stretch = tf.constant([[1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4]])\n",
        "\n",
        "print(x_stretch * y_stretch)  # Again, operator overloading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14KobqYu85gi"
      },
      "source": [
        "Most of the time, broadcasting is both time and space efficient, as the broadcast operation never materializes the expanded tensors in memory.  \n",
        "\n",
        "You see what broadcasting looks like using `tf.broadcast_to`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GW2Q59_r8hZ6",
        "outputId": "2612607a-ba9b-411c-af14-ca4571c79ba7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [1 2 3]\n",
            " [1 2 3]], shape=(3, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2bAMMQY-jpP"
      },
      "source": [
        "Unlike a mathematical op, for example, `broadcast_to` does nothing special to save memory.  Here, you are materializing the tensor.\n",
        "\n",
        "It can get even more complicated.  [This section](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html){:.external} of Jake VanderPlas's book _Python Data Science Handbook_ shows more broadcasting tricks (again in NumPy)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Rpz0xAsKSI"
      },
      "source": [
        "## tf.convert_to_tensor\n",
        "\n",
        "Most ops, like `tf.matmul` and `tf.reshape` take arguments of class `tf.Tensor`.  However, you'll notice in the above case, Python objects shaped like tensors are accepted.\n",
        "\n",
        "Most, but not all, ops call `convert_to_tensor` on non-tensor arguments.  There is a registry of conversions, and most object classes like NumPy's `ndarray`, `TensorShape`, Python lists, and `tf.Variable` will all convert automatically.\n",
        "\n",
        "See `tf.register_tensor_conversion_function` for more details, and if you have your own type you'd like to automatically convert to a tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05bBVBVYV0y6"
      },
      "source": [
        "## Ragged Tensors\n",
        "\n",
        "A tensor with variable numbers of elements along some axis is called \"ragged\". Use `tf.ragged.RaggedTensor` for ragged data.\n",
        "\n",
        "For example, This cannot be represented as a regular tensor:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPc3jGoeJqB7"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>A `tf.RaggedTensor`, shape: <code>[4, None]</code></th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/ragged.png?raw=1\" alt=\"A 2-axis ragged tensor, each row can have a different length.\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VsbTjoFfNVBF"
      },
      "outputs": [],
      "source": [
        "ragged_list = [\n",
        "    [0, 1, 2, 3],\n",
        "    [4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "p4xKTo57tutG",
        "outputId": "c8c26d6a-0c58-475b-c49b-255c8b5c54a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: Can't convert non-rectangular Python sequence to Tensor.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  tensor = tf.constant(ragged_list)\n",
        "except Exception as e:\n",
        "  print(f\"{type(e).__name__}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cm9KuEeMLGI"
      },
      "source": [
        "Instead create a `tf.RaggedTensor` using `tf.ragged.constant`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "XhF3QV3jiqTj",
        "outputId": "f9d0abb9-0906-4232-c358-17cb48b876ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>\n"
          ]
        }
      ],
      "source": [
        "ragged_tensor = tf.ragged.constant(ragged_list)\n",
        "print(ragged_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFgHduHVNoIE"
      },
      "source": [
        "The shape of a `tf.RaggedTensor` will contain some axes with unknown lengths:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Eo_3wJUWNgqB",
        "outputId": "dc1d7a86-8c92-4624-f668-895fcf57289b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, None)\n"
          ]
        }
      ],
      "source": [
        "print(ragged_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9njclVkkN7G"
      },
      "source": [
        "## String tensors\n",
        "\n",
        "`tf.string` is a `dtype`, which is to say you can represent data as strings (variable-length byte arrays) in tensors.\n",
        "\n",
        "The strings are atomic and cannot be indexed the way Python strings are. The length of the string is not one of the axes of the tensor. See `tf.strings` for functions to manipulate them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P_8spEGQ0wp"
      },
      "source": [
        "Here is a scalar string tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "sBosmM8MkIh4",
        "outputId": "4b0b2110-4884-4f19-e093-7e011b53a558",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Gray wolf', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Tensors can be strings, too here is a scalar string.\n",
        "scalar_string_tensor = tf.constant(\"Gray wolf\")\n",
        "print(scalar_string_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMFBSl1FQ3vE"
      },
      "source": [
        "And a vector of strings:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO-c3Tq3RC1L"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>A vector of strings, shape: <code>[3,]</code></th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/strings.png?raw=1\" alt=\"The string length is not one of the tensor's axes.\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "41Dv2kL9QrtO",
        "outputId": "d279948f-89db-4ede-b213-b08f25956c72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# If you have three string tensors of different lengths, this is OK.\n",
        "tensor_of_strings = tf.constant([\"Gray wolf\",\n",
        "                                 \"Quick brown fox\",\n",
        "                                 \"Lazy dog\"])\n",
        "# Note that the shape is (3,). The string length is not included.\n",
        "print(tensor_of_strings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76gQ9qrgSMzS"
      },
      "source": [
        "In the above printout the `b` prefix indicates that `tf.string` dtype is not a unicode string, but a byte-string. See the [Unicode Tutorial](https://www.tensorflow.org/tutorials/load_data/unicode) for more about working with unicode text in TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClSBPK-lZBQp"
      },
      "source": [
        "If you pass unicode characters they are utf-8 encoded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "GTgL53jxSMd9",
        "outputId": "20c7fbec-a212-46aa-bd01-761c31e2c9a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xf0\\x9f\\xa5\\xb3\\xf0\\x9f\\x91\\x8d'>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "tf.constant(\"🥳👍\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir9cY42MMAei"
      },
      "source": [
        "Some basic functions with strings can be found in `tf.strings`, including `tf.strings.split`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "8k2K0VTFyj8e",
        "outputId": "832d60bb-eac0-4b2a-b4b7-10321d2ac228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'Gray' b'wolf'], shape=(2,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# You can use split to split a string into a set of tensors\n",
        "print(tf.strings.split(scalar_string_tensor, sep=\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "zgGAn1dfR-04",
        "outputId": "61a872ad-4375-435d-8f8c-9c36152418cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]>\n"
          ]
        }
      ],
      "source": [
        "# ...but it turns into a `RaggedTensor` if you split up a tensor of strings,\n",
        "# as each string might be split into a different number of parts.\n",
        "print(tf.strings.split(tensor_of_strings))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsAn1kPeO84m"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>Three strings split, shape: <code>[3, None]</code></th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/string-split.png?raw=1\" alt=\"Splitting multiple strings returns a tf.RaggedTensor\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st9OxrUxWSKY"
      },
      "source": [
        "And `tf.string.to_number`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "3nRtx3X9WRfN",
        "outputId": "dc96d930-4d2f-4e92-8eea-8f93a73877d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([  1.  10. 100.], shape=(3,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "text = tf.constant(\"1 10 100\")\n",
        "print(tf.strings.to_number(tf.strings.split(text, \" \")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2EZtBbJBns4"
      },
      "source": [
        "Although you can't use `tf.cast` to turn a string tensor into numbers, you can convert it into bytes, and then into numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "fo8BjmH7gyTj",
        "outputId": "aeffa40f-1b15-421d-b2b2-b567b37bff10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)\n",
            "Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)\n"
          ]
        }
      ],
      "source": [
        "byte_strings = tf.strings.bytes_split(tf.constant(\"Duck\"))\n",
        "byte_ints = tf.io.decode_raw(tf.constant(\"Duck\"), tf.uint8)\n",
        "print(\"Byte strings:\", byte_strings)\n",
        "print(\"Bytes:\", byte_ints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "uSQnZ7d1jCSQ",
        "outputId": "20e2ea21-8823-4a51-fd80-b2c661d5fd07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unicode bytes: tf.Tensor(b'\\xe3\\x82\\xa2\\xe3\\x83\\x92\\xe3\\x83\\xab \\xf0\\x9f\\xa6\\x86', shape=(), dtype=string)\n",
            "\n",
            "Unicode chars: tf.Tensor([b'\\xe3\\x82\\xa2' b'\\xe3\\x83\\x92' b'\\xe3\\x83\\xab' b' ' b'\\xf0\\x9f\\xa6\\x86'], shape=(5,), dtype=string)\n",
            "\n",
            "Unicode values: tf.Tensor([ 12450  12498  12523     32 129414], shape=(5,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# Or split it up as unicode and then decode it\n",
        "unicode_bytes = tf.constant(\"アヒル 🦆\")\n",
        "unicode_char_bytes = tf.strings.unicode_split(unicode_bytes, \"UTF-8\")\n",
        "unicode_values = tf.strings.unicode_decode(unicode_bytes, \"UTF-8\")\n",
        "\n",
        "print(\"\\nUnicode bytes:\", unicode_bytes)\n",
        "print(\"\\nUnicode chars:\", unicode_char_bytes)\n",
        "print(\"\\nUnicode values:\", unicode_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE7nKJ2YW3aY"
      },
      "source": [
        "The `tf.string` dtype is used for all raw bytes data in TensorFlow. The `tf.io` module contains functions for converting data to and from bytes, including decoding images and parsing csv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua8BnAzxkRKV"
      },
      "source": [
        "## Sparse tensors\n",
        "\n",
        "Sometimes, your data is sparse, like a very wide embedding space.  TensorFlow supports `tf.sparse.SparseTensor` and related operations to store sparse data efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS5zgqgUTPRb"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>A `tf.SparseTensor`, shape: <code>[3, 4]</code></th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/sparse.png?raw=1\" alt=\"An 3x4 grid, with values in only two of the cells.\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "B9nbO1E2kSUN",
        "outputId": "66bb4502-a379-490e-92be-fdeb08629900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparseTensor(indices=tf.Tensor(\n",
            "[[0 0]\n",
            " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 0 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 0]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# Sparse tensors store values by index in a memory-efficient manner\n",
        "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
        "                                       values=[1, 2],\n",
        "                                       dense_shape=[3, 4])\n",
        "print(sparse_tensor, \"\\n\")\n",
        "\n",
        "# You can convert sparse tensors to dense\n",
        "print(tf.sparse.to_dense(sparse_tensor))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Tensorflow Primitives"
      ],
      "metadata": {
        "id": "CawAPf7fRXzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Einsum functions, where equation is a string representing the Einstein summation and operands is a sequence of tensors."
      ],
      "metadata": {
        "id": "tRnKwfe0R-NU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MATRIX TRANSPOSE"
      ],
      "metadata": {
        "id": "z8A5kdMyTNar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rank_2_tensor)"
      ],
      "metadata": {
        "id": "J8K--MPJTZ64",
        "outputId": "864a87ec-81a1-4697-a8f5-9eb30a7982c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]], shape=(3, 2), dtype=float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transpose = tf.einsum('ij->ji', rank_2_tensor)  # output[j,i] = m0[i,j]\n",
        "print(transpose)"
      ],
      "metadata": {
        "id": "ts6qQSg2TvrC",
        "outputId": "a3f861ce-861a-4113-b0c8-8fa342e14267",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 3. 5.]\n",
            " [2. 4. 6.]], shape=(2, 3), dtype=float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scalar Vector Multiplication"
      ],
      "metadata": {
        "id": "b2mijjWyV3Qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank_2_tensor2 = tf.constant([[7, 8],\n",
        "                             [9, 10],\n",
        "                             [11, 12]], dtype=tf.float16)\n",
        "print(rank_2_tensor2)"
      ],
      "metadata": {
        "id": "H9bSfh4MWhkX",
        "outputId": "8690cbc6-3d50-47da-b22e-c9b1ee2aa582",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 7.  8.]\n",
            " [ 9. 10.]\n",
            " [11. 12.]], shape=(3, 2), dtype=float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm = tf.einsum('ij,jk->ik', transpose, rank_2_tensor2)\n",
        "print(svm)\n",
        "print(svm.shape)"
      ],
      "metadata": {
        "id": "bAbHUtHIb-nq",
        "outputId": "76ffcdce-bcd7-4d54-c11c-4250dcc22ed8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 89.  98.]\n",
            " [116. 128.]], shape=(2, 2), dtype=float16)\n",
            "(2, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dot Product"
      ],
      "metadata": {
        "id": "oqm8FBvIdP90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = tf.random.normal(shape=[5])\n",
        "v = tf.random.normal(shape=[5])\n",
        "e = tf.einsum('i,i->', u, v)  # output = sum_i u[i]*v[i]\n",
        "print(u)\n",
        "print(v)\n",
        "print(e)"
      ],
      "metadata": {
        "id": "4d_bfejqdl11",
        "outputId": "a2a38944-bfad-42c8-e25d-03b74f0592c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([-0.20937236 -1.1080036  -1.4743278  -0.85630167  1.0348493 ], shape=(5,), dtype=float32)\n",
            "tf.Tensor([-0.61616176 -1.3100361   1.6593866  -0.4940094  -1.2663144 ], shape=(5,), dtype=float32)\n",
            "tf.Tensor(-1.7533714, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outer Product"
      ],
      "metadata": {
        "id": "mM52Th0SeKz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = tf.random.normal(shape=[3])\n",
        "t = tf.random.normal(shape=[5])\n",
        "d = tf.einsum('i,j->ij', s, t)  # output[i,j] = s[i]*t[j]\n",
        "i = tf.einsum('i,j->ij', t, s)\n",
        "print(s)\n",
        "print(t)\n",
        "print(d)\n",
        "print(i)\n",
        "print(e.shape)\n",
        "print(i.shape)"
      ],
      "metadata": {
        "id": "XVPCyGyfeQ9q",
        "outputId": "8848c8f4-e983-4670-e3d1-2322ced40bf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0.5969909  -0.9809371  -0.16671975], shape=(3,), dtype=float32)\n",
            "tf.Tensor([-0.46652576  2.013128   -1.2700075  -0.679298    1.2655107 ], shape=(5,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.2785116   1.2018191  -0.7581829  -0.4055347   0.75549835]\n",
            " [ 0.45763245 -1.9747521   1.2457975   0.66634864 -1.2413864 ]\n",
            " [ 0.07777906 -0.3356282   0.21173534  0.11325239 -0.21098563]], shape=(3, 5), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.2785116   0.45763245  0.07777906]\n",
            " [ 1.2018191  -1.9747521  -0.3356282 ]\n",
            " [-0.7581829   1.2457975   0.21173534]\n",
            " [-0.4055347   0.66634864  0.11325239]\n",
            " [ 0.75549835 -1.2413864  -0.21098563]], shape=(5, 3), dtype=float32)\n",
            "(3, 5)\n",
            "(5, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hadamard Product"
      ],
      "metadata": {
        "id": "RO3n3CbpfEBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank_2_tensor2\n",
        "h = tf.einsum('ij,ij->ij', rank_2_tensor, rank_2_tensor2)\n",
        "print(rank_2_tensor)\n",
        "print(rank_2_tensor2)\n",
        "print(h)\n"
      ],
      "metadata": {
        "id": "_RTwxImJfTsG",
        "outputId": "a46018be-9a49-486e-ac82-503cb799025a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]], shape=(3, 2), dtype=float16)\n",
            "tf.Tensor(\n",
            "[[ 7.  8.]\n",
            " [ 9. 10.]\n",
            " [11. 12.]], shape=(3, 2), dtype=float16)\n",
            "tf.Tensor(\n",
            "[[ 7. 16.]\n",
            " [27. 40.]\n",
            " [55. 72.]], shape=(3, 2), dtype=float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Matrix Multiplication"
      ],
      "metadata": {
        "id": "JzdXsz58gC5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank_3_tensor1 = tf.random.normal(shape=[3,5,2])\n",
        "rank_3_tensor2 = tf.random.normal(shape=[3,2,4])\n",
        "bmm = tf.einsum('bij,bjk->bik', rank_3_tensor1, rank_3_tensor2)\n",
        "bmm2 = tf.einsum('bij,bjk->bjk', rank_3_tensor1, rank_3_tensor2)\n",
        "bmm3 = tf.einsum('bij,bjk->bij', rank_3_tensor1, rank_3_tensor2)\n",
        "\n",
        "print(rank_3_tensor1)\n",
        "print(rank_3_tensor2)\n",
        "print(bmm)\n",
        "print(bmm2)\n",
        "print(bmm3)\n",
        "print(bmm.shape)\n",
        "print(bmm2.shape)\n",
        "print(bmm3.shape)"
      ],
      "metadata": {
        "id": "cVytL0jjgVyb",
        "outputId": "7deb16d3-a956-4fb0-c049-df5989e1bd26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[-0.22151487 -0.03077235]\n",
            "  [ 0.00850956 -0.50017405]\n",
            "  [-1.1830155  -1.1817917 ]\n",
            "  [-0.17143245  0.9166861 ]\n",
            "  [ 0.03608839 -0.2746952 ]]\n",
            "\n",
            " [[-0.8016905  -1.05775   ]\n",
            "  [-0.00837298  0.03150127]\n",
            "  [-0.29857597  0.37102383]\n",
            "  [ 0.2044458  -2.2836547 ]\n",
            "  [ 2.5309706  -0.15600932]]\n",
            "\n",
            " [[-2.3282113  -0.10488271]\n",
            "  [ 0.5949972   1.0646826 ]\n",
            "  [-0.06202976 -0.25311133]\n",
            "  [-0.5471379   0.69298965]\n",
            "  [-0.07388332 -1.0160289 ]]], shape=(3, 5, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 1.0654821  -2.0594077   0.41197518 -0.6756609 ]\n",
            "  [-0.0782856  -2.606887    0.30522928  0.3468331 ]]\n",
            "\n",
            " [[ 2.028934    0.8516062   0.13814251 -0.4501617 ]\n",
            "  [-0.14835738  0.367494    1.0546733  -1.5715405 ]]\n",
            "\n",
            " [[-0.8355644   0.9996806  -0.27348274 -0.22549693]\n",
            "  [ 0.98984     0.7417628   0.13828069 -0.6165563 ]]], shape=(3, 2, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[-2.3361111e-01  5.3640944e-01 -1.0065124e-01  1.3899606e-01]\n",
            "  [ 4.8223212e-02  1.2863727e+00 -1.4916204e-01 -1.7922650e-01]\n",
            "  [-1.1679646e+00  5.5171089e+00 -8.4809041e-01  3.8943282e-01]\n",
            "  [-2.5442153e-01 -2.0366480e+00  2.0917352e-01  4.3376732e-01]\n",
            "  [ 5.9956215e-02  6.4177859e-01 -6.8977490e-02 -1.1965690e-01]]\n",
            "\n",
            " [[-1.4696522e+00 -1.0714414e+00 -1.2263283e+00  2.0231872e+00]\n",
            "  [-2.1661662e-02  4.4460511e-03  3.2066889e-02 -4.5736335e-02]\n",
            "  [-6.6083503e-01 -1.1792013e-01  3.5006291e-01 -4.4867152e-01]\n",
            "  [ 7.5360405e-01 -6.6512203e-01 -2.3802671e+00  3.4968221e+00]\n",
            "  [ 5.1583176e+00  2.0980577e+00  1.8509576e-01 -8.9417106e-01]]\n",
            "\n",
            " [[ 1.8415533e+00 -2.4052658e+00  6.2222236e-01  5.8967060e-01]\n",
            "  [ 5.5670691e-01  1.3845491e+00 -1.5496433e-02 -7.9060680e-01]\n",
            "  [-1.9870986e-01 -2.4975853e-01 -1.8036339e-02  1.7004491e-01]\n",
            "  [ 1.1431178e+00 -3.2929182e-02  2.4545987e-01 -3.0388921e-01]\n",
            "  [-9.4397169e-01 -8.2751215e-01 -1.2029137e-01  6.4309943e-01]]], shape=(3, 5, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[-1.631642    3.1537046  -0.63088435  1.0346835 ]\n",
            "  [ 0.08382409  2.791317   -0.32682338 -0.37137055]]\n",
            "\n",
            " [[ 3.300623    1.3853734   0.22472705 -0.7323127 ]\n",
            "  [ 0.45914957 -1.137353   -3.2640965   4.863743  ]]\n",
            "\n",
            " [[ 2.018945   -2.4154932   0.6608068   0.54486036]\n",
            "  [ 0.37975147  0.28457683  0.0530513  -0.23654142]]], shape=(3, 2, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 0.2785796   0.06256358]\n",
            "  [-0.01070172  1.0169091 ]\n",
            "  [ 1.4877735   2.402713  ]\n",
            "  [ 0.21559538 -1.8637242 ]\n",
            "  [-0.04538517  0.5584857 ]]\n",
            "\n",
            " [[-2.059159    0.3149245 ]\n",
            "  [-0.02150616 -0.00937889]\n",
            "  [-0.76689863 -0.11046514]\n",
            "  [ 0.5251233   0.6799138 ]\n",
            "  [ 6.500851    0.04644874]]\n",
            "\n",
            " [[ 0.7796329  -0.13145235]\n",
            "  [-0.19924285  1.3343958 ]\n",
            "  [ 0.0207715  -0.31723133]\n",
            "  [ 0.18321651  0.8685428 ]\n",
            "  [ 0.02474082 -1.2734166 ]]], shape=(3, 5, 2), dtype=float32)\n",
            "(3, 5, 4)\n",
            "(3, 2, 4)\n",
            "(3, 5, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bilinear Transformation"
      ],
      "metadata": {
        "id": "Rk05bYAdoPwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r3t3 = tf.random.normal(shape=[3,5,2])\n",
        "r3t4 = tf.random.normal(shape=[3,2])\n",
        "r3t5 = tf.random.normal(shape=[4,6])\n",
        "bt = tf.einsum('ijk,ik,st->it', r3t3, r3t4, r3t5)\n",
        "print(bt)"
      ],
      "metadata": {
        "id": "K3SbKSV2oV6w",
        "outputId": "77c181f1-71e7-44b5-ec74-2b745fed8b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.0317594   0.04550273 -0.05557822 -0.08926317  0.12503207  0.00936644]\n",
            " [-0.9249563  -1.3252153   1.6186523   2.5996883  -3.6414165  -0.2727869 ]\n",
            " [ 1.4093597   2.019236   -2.466347   -3.9611557   5.548441    0.41564646]], shape=(3, 6), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Reduction ops"
      ],
      "metadata": {
        "id": "TGcg_QdhlMDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SUM\n"
      ],
      "metadata": {
        "id": "br6wdgMOlQ09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rank_2_tensor)\n",
        "r1 = tf.reduce_sum(rank_2_tensor)\n",
        "r3 = tf.reduce_sum(rank_2_tensor, axis = 0) ## same as sm_row = tf.einsum('ij->i', rank_2_tensor)\n",
        "r2 = tf.reduce_sum(rank_2_tensor, axis = 1) ## same as sm_col = tf.einsum('ij->j', rank_2_tensor)\n",
        "print(r1)\n",
        "print(r2)\n",
        "print(r3)\n",
        "sm = tf.einsum('ij->', rank_2_tensor)\n",
        "sm_col = tf.einsum('ij->j', rank_2_tensor)\n",
        "sm_row = tf.einsum('ij->i', rank_2_tensor)\n",
        "print(sm)\n",
        "print(sm_col)\n",
        "print(sm_row)"
      ],
      "metadata": {
        "id": "xtbL4VghlN64",
        "outputId": "e547ac49-961d-459b-c294-7278bb3362a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]], shape=(3, 2), dtype=float16)\n",
            "tf.Tensor(21.0, shape=(), dtype=float16)\n",
            "tf.Tensor([ 3.  7. 11.], shape=(3,), dtype=float16)\n",
            "tf.Tensor([ 9. 12.], shape=(2,), dtype=float16)\n",
            "tf.Tensor(21.0, shape=(), dtype=float16)\n",
            "tf.Tensor([ 9. 12.], shape=(2,), dtype=float16)\n",
            "tf.Tensor([ 3.  7. 11.], shape=(3,), dtype=float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Production"
      ],
      "metadata": {
        "id": "0gK5-hl5lxou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithms"
      ],
      "metadata": {
        "id": "kfoYNsi3xMuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear search"
      ],
      "metadata": {
        "id": "iHt8yN9nxM0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The time complexity of the Linear search is O(n). \n",
        "\n",
        "Step 1: First, read the search element (Target element) in the array.\n",
        "Step 2: In the second step compare the search element with the first element in the array.\n",
        "Step 3: If both are matched, display “Target element is found” and terminate the Linear Search \n",
        "function.\n",
        "Step 4: If both are not matched, compare the search element with the next element in the array.\n",
        "Step 5: In this step, repeat steps 3 and 4 until the search (Target) element is compared with the \n",
        "last element of the array.\n",
        "Step 6 – If the last element in the list does not match, the Linear Search Function will be \n",
        "terminated, and the message “Element is not found” will be displayed."
      ],
      "metadata": {
        "id": "etGDKrtg0sr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "class LinearSearch():\n",
        "    def __init__(self, array, x):\n",
        "        self.x = tf.constant(x)\n",
        "        self.array = tf.constant(array)\n",
        "        self.length = len(array)\n",
        "        self.graph = tf.while_loop(self.cond, self.body, [0, self.x, False],\n",
        "                            back_prop=False)\n",
        "\n",
        "    def run(self):\n",
        "        with tf.compat.v1.Session() as sess:\n",
        "            tf.compat.v1.global_variables_initializer().run()\n",
        "            return sess.run(self.graph)\n",
        "\n",
        "    def cond(self, i, _, is_found):\n",
        "        return tf.logical_and(tf.less(i, self.length), tf.logical_not(is_found))\n",
        "\n",
        "    def body(self, i, _, is_found):\n",
        "        return tf.cond(tf.equal(self.array[i], self.x),\n",
        "                    lambda: (i, self.array[i], True),\n",
        "                    lambda: (tf.add(i, 1), -1, False))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    array, x = [1, 7, 3, 8], 3\n",
        "    search = LinearSearch(array, x)\n",
        "    ix, xx, is_found = ret = search.run()\n",
        "    print('Array :', array)\n",
        "    print('Number to search :', x)\n",
        "    if is_found:\n",
        "        print('{} is at index {}.'.format(xx, ix))\n",
        "    else:\n",
        "        print('Not found.')"
      ],
      "metadata": {
        "id": "a84Qvs4rmkUc",
        "outputId": "fbc7d841-243c-4d82-c2f8-1eb2b50628e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array : [1, 7, 3, 8]\n",
            "Number to search : 3\n",
            "3 is at index 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insertion Sort"
      ],
      "metadata": {
        "id": "sgYWGM9cy1Eh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This algorithm sorts an array of items by repeatedly taking an element from the unsorted portion of the array and inserting it into its correct position in the sorted portion of the array.\n",
        "\n",
        "The procedure takes a single argument, ‘A’, which is a list of sortable items.\n",
        "The variable ‘n’ is assigned the length of the array A.\n",
        "The outer for loop starts at index ‘1’ and runs for ‘n-1’ iterations, where ‘n’ is the length of the array.\n",
        "The inner while loop starts at the current index i of the outer for loop and compares each element to its left neighbor. If an element is smaller than its left neighbor, the elements are swapped.\n",
        "The inner while loop continues to move an element to the left as long as it is smaller than the element to its left.\n",
        "Once the inner while loop is finished, the element at the current index is in its correct position in the sorted portion of the array.\n",
        "The outer for loop continues iterating through the array until all elements are in their correct positions and the array is fully sorted."
      ],
      "metadata": {
        "id": "IY-qKKRf2jAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "np.random.seed(123)\n",
        "\n",
        "class InsertionSort():\n",
        "    def __init__(self, array):\n",
        "        self.i = tf.constant(1)\n",
        "        self.j = tf.constant(len(array)-1)\n",
        "        self.array = tf.Variable(array, trainable=False)\n",
        "        self.length = len(array)\n",
        "\n",
        "        cond = lambda i, j, _: tf.less(i-1, self.length-1)\n",
        "        self.graph = tf.while_loop(cond, self.outer_loop, loop_vars=[self.i, self.j, self.array],\n",
        "                shape_invariants=[self.i.get_shape(), self.j.get_shape(), tf.TensorShape(self.length)],\n",
        "                parallel_iterations=1,\n",
        "                back_prop=False)\n",
        "\n",
        "    def run(self):\n",
        "        with tf.compat.v1.Session() as sess:\n",
        "            tf.compat.v1.global_variables_initializer().run()\n",
        "            return sess.run(self.graph)\n",
        "\n",
        "    def outer_loop(self, i, j, _):\n",
        "        j = i\n",
        "        cond = lambda i, j, array: tf.logical_and(tf.greater(j,0), tf.greater(array[j-1], array[j]))\n",
        "\n",
        "        loop = tf.while_loop(cond, self.inner_loop, loop_vars=[i, j, self.array],\n",
        "                    shape_invariants=[i.get_shape(), j.get_shape(), tf.TensorShape(self.length)],\n",
        "                    parallel_iterations=1,\n",
        "                    back_prop=False)\n",
        "        return tf.add(i, 1), loop[1], loop[2]\n",
        "\n",
        "    def inner_loop(self, i, j, _):\n",
        "        return i, tf.subtract(j, 1), tf.compat.v1.scatter_nd_update(self.array, [[j-1],[j]], [self.array[j],self.array[j-1]])\n",
        "\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    x = np.array([1.,7.,3.,8.])\n",
        "    print(x)\n",
        "    print(InsertionSort(x).run()[2])\n",
        "    y = np.random.rand(10)\n",
        "    print(y)\n",
        "    print(InsertionSort(y).run()[2])"
      ],
      "metadata": {
        "id": "wT--dad1y4b_",
        "outputId": "1906eb04-79c5-4aff-c279-2c852db66e91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 7. 3. 8.]\n",
            "[1. 3. 7. 8.]\n",
            "[0.69646919 0.28613933 0.22685145 0.55131477 0.71946897 0.42310646\n",
            " 0.9807642  0.68482974 0.4809319  0.39211752]\n",
            "[0.22685145 0.28613933 0.39211752 0.42310646 0.4809319  0.55131477\n",
            " 0.68482974 0.69646919 0.71946897 0.9807642 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary search"
      ],
      "metadata": {
        "id": "FQZxmmNwzk79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea of binary search is to use the information that the array is sorted and reduce the time complexity to O(Log n). \n",
        "\n",
        "Binary Search Algorithm: The basic steps to perform Binary Search are:\n",
        "\n",
        "Sort the array in ascending order.\n",
        "Set the low index to the first element of the array and the high index to the last element.\n",
        "Set the middle index to the average of the low and high indices.\n",
        "If the element at the middle index is the target element, return the middle index.\n",
        "If the target element is less than the element at the middle index, set the high index to the middle index – 1.\n",
        "If the target element is greater than the element at the middle index, set the low index to the middle index + 1.\n",
        "Repeat steps 3-6 until the element is found or it is clear that the element is not present in the array."
      ],
      "metadata": {
        "id": "u3EyJuUu0qVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BinarySearch():\n",
        "    def __init__(self, array, x):\n",
        "        self.array = tf.constant(array)\n",
        "        self.x = tf.constant(x)\n",
        "        self.loop = tf.while_loop(self.cond, self.body, [-1,False,0,len(array),-1],\n",
        "                        back_prop=False)\n",
        "\n",
        "    def run(self):\n",
        "        with tf.compat.v1.Session() as sess:\n",
        "            tf.compat.v1.global_variables_initializer().run()\n",
        "            return sess.run(self.loop)\n",
        "\n",
        "    def cond(self, x, is_found, left, right, mid):\n",
        "        return tf.logical_and(tf.less_equal(left, right), tf.logical_not(is_found))\n",
        "\n",
        "    def body(self, x, is_found, left, right, mid):\n",
        "        mid = tf.compat.v1.to_int32(tf.divide(tf.add(left, right), 2))\n",
        "        return tf.cond(tf.equal(self.array[mid], self.x),\n",
        "                    lambda: (self.array[mid], True, left, right, mid),\n",
        "                    lambda: tf.cond(tf.less(self.array[mid], self.x),\n",
        "                                lambda: (-1, False, tf.add(mid, 1), right, mid),\n",
        "                                lambda: (-1, False, left, tf.subtract(mid, 1), mid)))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    array = sorted([1, 7, 3, 8, 5])\n",
        "    x = 8\n",
        "    search = BinarySearch(array, x)\n",
        "    xx, is_found, l, r, m = search.run()\n",
        "\n",
        "    print('Array :', array)\n",
        "    print('Number to search :', x)\n",
        "    if is_found:\n",
        "        print('{} is at index {}.'.format(xx, m))\n",
        "    else:\n",
        "        print('Not found.')"
      ],
      "metadata": {
        "id": "mXacMqPszoVq",
        "outputId": "4f9acef5-4ab4-4d10-a8ca-e68c474521a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array : [1, 3, 5, 7, 8]\n",
            "Number to search : 8\n",
            "8 is at index 4.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "tensor.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}